import streamlit as st
from openai import OpenAI
import glob  
import sys
import subprocess

# ğŸ”¹ Kiá»ƒm tra vÃ  cÃ i Ä‘áº·t `tiktoken` náº¿u chÆ°a cÃ³
try:
    import tiktoken
except ModuleNotFoundError:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "tiktoken"])
    import tiktoken  

# ğŸ”¹ HÃ m Ä‘á»c ná»™i dung tá»« nhiá»u file vÃ  ghÃ©p láº¡i
def read_multiple_files(pattern):
    content = []
    files = sorted(glob.glob(pattern))  
    for file in files:
        with open(file, "r", encoding="utf-8") as f:
            content.append(f.read().strip())  
    return "\n\n".join(content)  

# ğŸ”¹ HÃ m Ä‘áº¿m sá»‘ tokens
def count_tokens(text):
    encoding = tiktoken.get_encoding("cl100k_base")  # DÃ¹ng tokenizer GPT-4
    return len(encoding.encode(text))

# ğŸ”¹ HÃ m rÃºt gá»n ná»™i dung náº¿u vÆ°á»£t quÃ¡ sá»‘ token cho phÃ©p
def truncate_text(text, max_tokens=1000):
    encoding = tiktoken.get_encoding("cl100k_base")
    tokens = encoding.encode(text)
    truncated_tokens = tokens[:max_tokens]  # Giá»¯ láº¡i tá»‘i Ä‘a max_tokens tokens
    return encoding.decode(truncated_tokens)

# ğŸ“Œ Hiá»ƒn thá»‹ logo
col1, col2, col3 = st.columns([3, 2, 3])
with col2:
    st.image("logo.png", use_container_width=True)

# ğŸ“Œ Hiá»ƒn thá»‹ tiÃªu Ä‘á» tá»« file
title_content = read_multiple_files("00.xinchao.txt")
st.markdown(f"<h1 style='text-align: center; font-size: 24px;'>{title_content}</h1>", unsafe_allow_html=True)

# ğŸ“Œ Láº¥y OpenAI API key
openai_api_key = st.secrets.get("OPENAI_API_KEY")

# ğŸ“Œ Táº¡o OpenAI client
client = OpenAI(api_key=openai_api_key)

# ğŸ”¹ Äá»c vÃ  rÃºt gá»n ná»™i dung há»‡ thá»‘ng náº¿u quÃ¡ dÃ i
system_content = read_multiple_files("01*.system_trainning.txt")
if count_tokens(system_content) > 1000:
    system_content = truncate_text(system_content, 1000)  # RÃºt gá»n náº¿u quÃ¡ dÃ i
INITIAL_SYSTEM_MESSAGE = {"role": "system", "content": system_content}

# ğŸ”¹ Äá»c ná»™i dung trá»£ lÃ½
assistant_content = read_multiple_files("02.assistant.txt")
INITIAL_ASSISTANT_MESSAGE = {"role": "assistant", "content": assistant_content}

# ğŸ”¹ Giá»›i háº¡n chá»‰ giá»¯ láº¡i 5-7 tin nháº¯n gáº§n nháº¥t
MAX_MESSAGES = 7  

if "messages" not in st.session_state:
    st.session_state.messages = [INITIAL_SYSTEM_MESSAGE, INITIAL_ASSISTANT_MESSAGE]

# ğŸ“Œ Chá»‰ giá»¯ láº¡i 7 tin nháº¯n gáº§n nháº¥t Ä‘á»ƒ trÃ¡nh lá»—i context length
st.session_state.messages = st.session_state.messages[-MAX_MESSAGES:]

# ğŸ“Œ Hiá»ƒn thá»‹ tin nháº¯n cÅ©
for message in st.session_state.messages:
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# ğŸ“Œ Nháº­p ná»™i dung má»›i tá»« ngÆ°á»i dÃ¹ng
if prompt := st.chat_input("Báº¡n nháº­p ná»™i dung cáº§n trao Ä‘á»•i á»Ÿ Ä‘Ã¢y nhÃ©?"):

    # ğŸ”¹ LÆ°u vÃ  hiá»ƒn thá»‹ tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ğŸ”¹ Chá»‰ giá»¯ láº¡i 7 tin nháº¯n gáº§n nháº¥t trÆ°á»›c khi gá»­i Ä‘áº¿n OpenAI
    messages_to_send = st.session_state.messages[-MAX_MESSAGES:]

    # ğŸ”¹ Gá»­i tin nháº¯n Ä‘áº¿n OpenAI API
    try:
        stream = client.chat.completions.create(
            model=read_multiple_files("module_chatgpt.txt").strip(),
            messages=[{"role": m["role"], "content": m["content"]} for m in messages_to_send],
            stream=True,
        )

        # ğŸ“Œ Hiá»ƒn thá»‹ pháº£n há»“i cá»§a trá»£ lÃ½
        with st.chat_message("assistant"):
            response_text = ""
            for chunk in stream:
                if chunk.choices:
                    response_text += chunk.choices[0].delta.content or ""  

            st.markdown(response_text)

        # ğŸ”¹ LÆ°u pháº£n há»“i cá»§a trá»£ lÃ½ vÃ o session
        st.session_state.messages.append({"role": "assistant", "content": response_text})

    except Exception as e:
        st.error(f"Lá»—i khi gá»i OpenAI API: {str(e)}")
